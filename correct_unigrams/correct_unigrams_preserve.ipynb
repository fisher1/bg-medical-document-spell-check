{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv('dictionary_2.csv')\n",
    "complaints = pd.read_csv('./fmi_symptom_recognition/data/complaints.csv')\n",
    "organs = pd.read_csv('./fmi_symptom_recognition/data/organs.csv')\n",
    "symptoms = pd.read_csv('./fmi_symptom_recognition/data/symptoms.csv')\n",
    "systems = pd.read_csv('./fmi_symptom_recognition/data/systems.csv')\n",
    "\n",
    "dictionary = pd.concat([dictionary, complaints, organs, symptoms, systems], ignore_index=True)\n",
    "\n",
    "df = pd.read_excel('unigrams.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark by single correct word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11653\n"
     ]
    }
   ],
   "source": [
    "correct_single = df['Word'].str.lower().isin(dictionary['name'])\n",
    "df['Correct auto'] = correct_single\n",
    "print(len(df[df['Correct auto'] == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean by joined correct words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13456\n"
     ]
    }
   ],
   "source": [
    "dictionary_dict = dictionary['name'].to_dict()\n",
    "dictionary_dict = {v: k for k, v in dictionary_dict.items()}\n",
    "\n",
    "def check_split_words_in_dictionary(unigram):\n",
    "    words = re.sub(r\"[\\.\\-]\", ' ', str(unigram)).split()\n",
    "    for word in words:\n",
    "        if word not in dictionary_dict:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "split_words = df['Word'].apply(check_split_words_in_dictionary)\n",
    "df['Correct auto'] += split_words\n",
    "print(len(df[df['Correct auto'] == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark incorrectly joined words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0              Word  Count  Correct  Link to correct  \\\n",
      "0               0                 и  31679    False              NaN   \n",
      "1               1                на  27252    False              NaN   \n",
      "2               2               без  27204    False              NaN   \n",
      "3               3               б.о  22399    False              NaN   \n",
      "4               4                RR  22049    False              NaN   \n",
      "...           ...               ...    ...      ...              ...   \n",
      "43284       31484  XII.Десностранна      1    False              NaN   \n",
      "43285       33836               xsl      1    False              NaN   \n",
      "43286       36530                 z      1    False              NaN   \n",
      "43287       22400                Za      1    False              NaN   \n",
      "43288       40010          ZASTOJNI      1    False              NaN   \n",
      "\n",
      "         BG to EN    EN to BG  Correct auto split_suggestions  \n",
      "0             and           и          True              None  \n",
      "1              on          На          True              None  \n",
      "2         without         без          True              None  \n",
      "3             b.o         B.O         False              None  \n",
      "4              Rr          RR         False              None  \n",
      "...           ...         ...           ...               ...  \n",
      "43284  XII.Dexual  Xii.dexual         False              None  \n",
      "43285         xsl         xsl         False              None  \n",
      "43286           z           z         False              None  \n",
      "43287          Za          За         False              None  \n",
      "43288    Zastojni    Zastojni         False              None  \n",
      "\n",
      "[43289 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "def check_joined_words_in_dictionary(unigram):\n",
    "    unigram = str(unigram)\n",
    "    # if not single word, it was already checked at previous step\n",
    "    if not re.match(r\"[а-яА-Яa-zA-Z]+\", unigram):\n",
    "        return False\n",
    "\n",
    "    for i in range(1, len(unigram)):\n",
    "        word1 = unigram[0:i]\n",
    "        word2 = unigram[i:len(unigram)]\n",
    "        if word1 in dictionary_dict and word2 in dictionary_dict:\n",
    "            return word1 + ' ' + word2\n",
    "\n",
    "    return None\n",
    "\n",
    "joined_words = df['Word'].apply(check_joined_words_in_dictionary)\n",
    "df = df.assign(split_suggestions=joined_words)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translated similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17308\n"
     ]
    }
   ],
   "source": [
    "def get_similarity(row):\n",
    "    if row['Correct auto']:\n",
    "        return None\n",
    "    \n",
    "    original = str(row['Word']).lower()\n",
    "    translated = str(row['EN to BG']).lower()\n",
    "\n",
    "    i = 0\n",
    "    same_count = 0\n",
    "    while i < len(original) and i < len(translated):\n",
    "        if original[i] == translated[i]:\n",
    "            same_count += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    bigger = max(len(original), len(translated))\n",
    "    return same_count/bigger\n",
    "\n",
    "similarity = df.apply(get_similarity, axis=1)\n",
    "df = df.assign(translated_similarity=similarity)\n",
    "df['Correct auto similarity'] = df['Correct auto'] + (df['translated_similarity'] >= 0.8)\n",
    "print(len(df[df['Correct auto similarity'] == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark certainly incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "dictionary_items_list = dictionary['name'].to_dict().values()\n",
    "dictionary_bucket = {}\n",
    "for item in dictionary_items_list:\n",
    "    str_item = str(item)\n",
    "    if len(str_item) < 3: continue\n",
    "    first_letter = str_item[0]\n",
    "    if first_letter not in dictionary_bucket:\n",
    "        dictionary_bucket[first_letter] = {}\n",
    "    second_letter = str_item[1]\n",
    "    if second_letter not in dictionary_bucket[first_letter]:\n",
    "        dictionary_bucket[first_letter][second_letter] = []\n",
    "    dictionary_bucket[first_letter][second_letter].append(item)\n",
    "\n",
    "def get_incorrect(row):\n",
    "    unigram = str(row['Word'])\n",
    "    if len(unigram) < 3 or row['Correct auto similarity'] or row['Correct']:\n",
    "        return False\n",
    "\n",
    "    first_letter = unigram[0].lower()\n",
    "    second_letter = unigram[1].lower()\n",
    "    if first_letter not in dictionary_bucket:\n",
    "        return False\n",
    "    if second_letter not in dictionary_bucket[first_letter]:\n",
    "        return False\n",
    "    \n",
    "    for word in dictionary_bucket[first_letter][second_letter]:\n",
    "        distance = jaccard_distance(set(unigram), set(word))\n",
    "        if distance < 0.1:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "incorrect = df.apply(get_incorrect, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3318\n"
     ]
    }
   ],
   "source": [
    "df['Incorrect auto'] = incorrect\n",
    "print(len(df[df['Incorrect auto'] == True]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract to XLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('unigrams_new.xlsx')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
