{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data_per_simpCode_00_clean_anamnesa.txt', 'rb') as f:\n",
    "    lines = f.read().decode(\"utf-8\", \"backslashreplace\").splitlines()\n",
    "df = pd.DataFrame(lines, dtype='string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean with regular expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numbers(sentence):\n",
    "    return re.sub('\\d+', 'NUM', sentence)\n",
    "\n",
    "def replace_dates(sentence):\n",
    "    return re.sub('NUM.NUM.NUM', 'DATE', sentence)\n",
    "\n",
    "def replace_float_numbers(sentence):\n",
    "    return re.sub('NUM.NUM', 'NUM', sentence)\n",
    "\n",
    "def remove_multiple_spaces(sentence):\n",
    "    return re.sub('\\s+', ' ', sentence)\n",
    "\n",
    "def remove_multiple_tabs(sentence):\n",
    "    return re.sub('\\t+', ' ', sentence)\n",
    "\n",
    "def space_out_semicolon(sentence):\n",
    "    return re.sub(';', ' ; ', sentence)\n",
    "\n",
    "def add_space_before_numbers(sentence):\n",
    "    return re.sub(r\"(\\w+)NUM\", r\"\\1 NUM\", sentence)\n",
    "\n",
    "def add_space_after_numbers(sentence):\n",
    "    return re.sub(r\"NUM(\\w+)\", r\"NUM \\1\", sentence)\n",
    "\n",
    "def remove_semicolons(sentence):\n",
    "    return re.sub(';', ' ', sentence)\n",
    "\n",
    "def remove_colons(sentence):\n",
    "    return re.sub(':', ' ', sentence)\n",
    "\n",
    "def remove_commas(sentence):\n",
    "    return re.sub('\\,', ' ', sentence)\n",
    "\n",
    "def remove_slashes(sentence):\n",
    "    return re.sub('\\/+', ' ', sentence)\n",
    "\n",
    "def remove_backslashes(sentence):\n",
    "    return re.sub('\\\\\\\\+', ' ', sentence)\n",
    "\n",
    "def remove_plus_signs(sentence):\n",
    "    return re.sub('\\+', ' ', sentence)\n",
    "\n",
    "def remove_underscores(sentence):\n",
    "    return re.sub('\\_', ' ', sentence)\n",
    "\n",
    "def replace_invalid_dash(sentence):\n",
    "    return re.sub('–', '-', sentence)\n",
    "\n",
    "def replace_multiple_dashes(sentence):\n",
    "    return re.sub('-{2,}', ' - ', sentence)\n",
    "\n",
    "def replace_multiple_dots(sentence):\n",
    "    return re.sub('\\.{2,}', '.', sentence)\n",
    "\n",
    "def remove_dashes_followed_by_space(sentence):\n",
    "    return re.sub(r\"(.)-\\s\", r\"\\1 \", sentence)\n",
    "\n",
    "def remove_dashes_following_a_space(sentence):\n",
    "    return re.sub(r\"\\s-(.)\", r\" \\1\", sentence)\n",
    "\n",
    "def remove_negative_examination(sentence):\n",
    "    return re.sub('\\(-\\)', ' ', sentence)\n",
    "\n",
    "def remove_starting_special_characters(sentence):\n",
    "    return re.sub('^[\\.\\?\\-,]+', '', sentence)\n",
    "\n",
    "def remove_ending_special_characters(sentence):\n",
    "    return re.sub('[\\.\\?\\-,]+$', '', sentence)\n",
    "\n",
    "def remove_dots(sentence):\n",
    "    return re.sub('[\\.]+', ' ', sentence)\n",
    "\n",
    "def remove_quotation_marks(sentence):\n",
    "    return re.sub('[\\`\\'\\\"]+', ' ', sentence)\n",
    "\n",
    "def remove_dot_before_word(sentence):\n",
    "    return re.sub(r\"([^\\wа-яА-Я])\\.([\\wа-яА-Я])\", r\"\\1 \\2\", sentence)\n",
    "\n",
    "def remove_dot_followed_by_dash(sentence):\n",
    "    return re.sub(r\"\\.\\-\", '. ', sentence)\n",
    "\n",
    "def space_out_dot_before_number(sentence):\n",
    "    return re.sub(r\"[\\.][\\-=]NUM\", '. NUM', sentence)\n",
    "\n",
    "def split_words_with_capital_after_lowercase(sentence):\n",
    "    return re.sub(r\"([а-яa-z])([А-ЯA-Z])\", r\"\\1 \\2\", sentence)\n",
    "\n",
    "\n",
    "df['clean_sentence'] = df[0].apply(remove_semicolons)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_colons)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_commas)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_slashes)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_backslashes)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_plus_signs)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_underscores)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_invalid_dash)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_multiple_dashes)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_multiple_dots)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_followed_by_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_following_a_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_negative_examination)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_starting_special_characters)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_ending_special_characters)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_dates)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_float_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(add_space_before_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(add_space_after_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(space_out_dot_before_number)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dot_before_word)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dot_followed_by_dash)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(split_words_with_capital_after_lowercase)\n",
    "# df['clean_sentence'] = df['clean_sentence'].apply(remove_dots) # commetnt this line\n",
    "# df['clean_sentence'] = df['clean_sentence'].apply(space_out_semicolon)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_quotation_marks)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_multiple_tabs)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_multiple_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special cases cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dash_after_special_words(sentence):\n",
    "    special_words = [\n",
    "        'апарат', 'вени', 'възли', 'глава', 'гърло', 'далак', 'дейност', 'дроб', 'език',\n",
    "        'жлеза', 'жлези', 'зрение', 'кожа', 'корем', 'крайници', 'нос', 'ода', 'одс', \n",
    "        'простата', 'пулмо', 'пулс', 'рефлекси', 'с-ма', 'слезка', 'сливици', \n",
    "        'слух', 'статус', 'сърце', 'състояние',\n",
    "        'тегло', 'температура', 'тонзили', 'шия', 'чмн', 'rr']\n",
    "    for word in special_words:\n",
    "        sentence = re.sub(f\"({word})-\", r\"\\1 \", sentence, flags=re.IGNORECASE)\n",
    "    return sentence\n",
    "\n",
    "def replace_special_expressions(sentence):\n",
    "    special_expressions = [\n",
    "        ['V O S', 'VOS'],\n",
    "        ['V O D', 'VOD'],\n",
    "        [r\"([^\\wа-яА-Я])(?:рр|РР|Рр|rr|PP)\", r\"\\1 RR\"],\n",
    "        [r\"(?:рр|РР|Рр|rr|PP)([^\\wа-яА-Я])\", r\"RR \\1\"],\n",
    "        [r\"([^\\wа-яА-Я]*)(?:кор|Кор|КОР|kor|Кор)([^\\wа-яА-Я])\", r\"\\1 Cor \"],\n",
    "        [r\"(?:б\\.о\\.|\\sБО\\s|\\sБо\\s|\\sбо\\s|\\sб\\sо\\s|\\sБ\\sО\\s)\", ' б.о. '],\n",
    "        [r\"(?:РСД|р\\.с\\.д\\.|рсд|PCД)\", ' РСД '],\n",
    "        ['ССС', ' ССС '],\n",
    "    ]\n",
    "    for find, replace in special_expressions:\n",
    "        sentence = re.sub(find, replace, sentence)\n",
    "    return sentence\n",
    "\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dash_after_special_words)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_special_expressions)\n",
    "\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_followed_by_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_following_a_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dot_before_word)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_multiple_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Unigrams length====\n",
      "8722\n",
      "====First 50 unigrams====\n",
      "[('на', 3807), ('в', 2078), ('от', 2005), ('се', 1929), ('за', 1880), ('и', 1871), ('с', 1502), ('по', 832), ('е', 739), ('Оплаква', 604), ('лечение', 549), ('болки', 533), ('повод', 468), ('при', 435), ('терапия', 431), ('преглед', 403), ('да', 371), ('болка', 314), ('не', 309), ('оплаквания', 305), ('От', 298), ('С', 296), ('след', 269), ('изписване', 266), ('За', 241), ('главоболие', 229), ('години', 215), ('има', 206), ('След', 197), ('оплаква', 197), ('редовно', 196), ('без', 196), ('лекарства', 193), ('г.', 191), ('отпадналост', 185), ('карцином', 185), ('със', 183), ('химиотерапия', 179), ('Са', 177), ('кашлица', 176), ('контрол', 175), ('корема', 172), ('контролен', 167), ('област', 166), ('лесна', 163), ('хоспитализация', 162), ('На', 162), ('умора', 162), ('изследвания', 160), ('хипертония', 158)]\n",
      "====First 50 bigrams====\n",
      "[(('се', 'от'), 756), (('Оплаква', 'се'), 597), (('по', 'повод'), 415), (('болки', 'в'), 412), (('се', 'за'), 258), (('изписване', 'на'), 258), (('болка', 'в'), 220), (('контролен', 'преглед'), 157), (('от', 'болки'), 155), (('за', 'изписване'), 139), (('карцином', 'на'), 135), (('може', 'да'), 132), (('Са', 'на'), 131), (('в', 'корема'), 129), (('не', 'може'), 127), (('консултация', 'с'), 125), (('се', 'оплаква'), 122), (('на', 'лекарства'), 116), (('лесна', 'умора'), 115), (('!', '!'), 114), (('да', 'се'), 113), (('оплаква', 'от'), 111), (('от', 'болка'), 108), (('контрол', 'на'), 108), (('стойности', 'на'), 104), (('е', 'с'), 99), (('оплаквания', 'от'), 94), (('Идва', 'за'), 91), (('в', 'кръста'), 91), (('за', 'хоспитализация'), 86), (('оперативно', 'лечение'), 85), (('областта', 'на'), 82), (('Съобщава', 'за'), 81), (('под', 'терапия'), 81), (('в', 'областта'), 79), (('оплаква', 'се'), 79), (('не', 'е'), 79), (('се', 'на'), 78), (('Явява', 'се'), 78), (('Насочва', 'се'), 77), (('данни', 'за'), 75), (('?', '?'), 75), (('на', 'лява'), 74), (('на', 'под'), 74), (('тежест', 'в'), 73), (('лечение', 'с'), 72), (('от', 'главоболие'), 70), (('често', 'уриниране'), 69), (('на', 'DATE'), 69), (('в', 'гърдите'), 68)]\n"
     ]
    }
   ],
   "source": [
    "# save cleaned data so we know what tokenizer works on\n",
    "df['clean_sentence'].to_csv('sentence_cleaned_anamnesa.csv')\n",
    "\n",
    "discarded_tokens = ['.', 'NUM', 'DATE']\n",
    "\n",
    "unigrams = {}\n",
    "bigrams = {}\n",
    "for sentence in df['clean_sentence']:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = list(filter(lambda token: token not in discarded_tokens, tokens))\n",
    "\n",
    "    #get unigrams\n",
    "    for token in tokens:\n",
    "        if token not in unigrams:\n",
    "            unigrams[token] = 0\n",
    "        unigrams[token] += 1\n",
    "\n",
    "    #get bigrams\n",
    "    bigram_list = list(ngrams(tokens, 2))\n",
    "    for bigram in bigram_list:\n",
    "        if bigram not in bigrams:\n",
    "            bigrams[bigram] = 0\n",
    "        bigrams[bigram] += 1\n",
    "\n",
    "unigrams = sorted(unigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "bigrams = sorted(bigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "print('====Unigrams length====')\n",
    "print(len(unigrams))\n",
    "print('====First 50 unigrams====')\n",
    "print(unigrams[0:50])\n",
    "print('====First 50 bigrams====')\n",
    "print(bigrams[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Collocations length====\n",
      "341\n",
      "====First 50 collocations====\n",
      "[('може', 'да'), ('Явява', 'се'), ('условията', 'на'), ('на', 'извънболничната'), ('извънболничната', 'помощ'), ('се', 'постигне'), ('тъй', 'като'), ('да', 'заплати'), ('заплати', 'при'), ('при', 'назначаването'), ('назначаването', 'им'), ('с', 'бланка'), ('Лечебната', 'цел'), ('да', 'бъда'), ('бъда', 'диспансеризиран'), ('да', 'осигури'), ('осигури', 'достатъчен'), ('достатъчен', 'РС'), ('РС', 'а'), ('Не', 'желая'), ('желая', 'да'), ('за', 'преписване'), ('преписване', 'на'), ('шум', 'в'), ('млечна', 'жлеза'), ('с', 'оглед'), ('взет', 'на'), ('е', 'съгласен'), ('съгласен', 'да'), ('на', 'Диспансерно'), ('начин', 'на'), ('провеждане', 'на'), ('назначената', 'терапия'), ('по', 'хода'), ('издаване', 'на'), ('Административно', 'посещение'), ('Води', 'се'), ('наличие', 'на'), ('Преглед', 'за'), ('на', 'Артериалното'), ('подд.мес', 'терапия'), ('рискови', 'фактори'), ('при', 'обичайни'), ('сухота', 'в'), ('направление', 'за'), ('заседнал', 'начин'), ('на', 'живот'), ('кръвното', 'налягане'), ('в', 'сърд'), ('ОПЛАКВА', 'СЕ')]\n"
     ]
    }
   ],
   "source": [
    "def get_collocations(bigrams, freq_threshold=1):\n",
    "    collocations = []\n",
    "\n",
    "    bigram_map_first_word = {}\n",
    "    bigram_map_second_word = {}\n",
    "    for bigram, _ in bigrams:\n",
    "        if bigram[0] not in bigram_map_first_word:\n",
    "            bigram_map_first_word[bigram[0]] = 0\n",
    "        bigram_map_first_word[bigram[0]] += 1\n",
    "        if bigram[1] not in bigram_map_second_word:\n",
    "            bigram_map_second_word[bigram[1]] = 0\n",
    "        bigram_map_second_word[bigram[1]] += 1\n",
    "\n",
    "    for bigram, freq in bigrams:\n",
    "        if freq < freq_threshold:\n",
    "            continue\n",
    "        if bigram_map_first_word[bigram[0]] == 1 or bigram_map_second_word[bigram[1]] == 1:\n",
    "            collocations.append(bigram)\n",
    "\n",
    "    return collocations\n",
    "\n",
    "collocations = get_collocations(bigrams, 5)\n",
    "\n",
    "print('====Collocations length====')\n",
    "print(len(collocations))\n",
    "print('====First 50 collocations====')\n",
    "print(collocations[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====First 50 unigram mistakes====\n",
      "[{'Оплаква': []}, {'лечение': ['лечени', 'лечиние', 'личен']}, {'болки': ['иболки', 'блоки', 'облки', 'боилки']}, {'повод': ['повоод']}, {'при': ['прии']}, {'терапия': ['терапията', 'артерия', 'приета', 'теряапия', 'терарпия', 'Терапията', 'тераипята', 'периартри', 'препарати', 'терапи', 'теряапи', 'неприятна', 'периартрит']}, {'преглед': ['прегледа', 'прегледи', 'преглд']}, {'болка': ['облак', 'болака', 'болак']}, {'оплаквания': ['оплакванията', 'оплакваниея', 'плаквания', 'оплаквния', 'аплаквания', 'оплакваяния', 'оплакавания', 'оплакваниья', 'оплаквани', 'оплакванишя']}, {'след': []}, {'изписване': ['изсписване', 'исписване', 'изпислване', 'из-писване', 'изсипване', 'изписане', 'заспиване', 'неспазване', 'Заизписване', 'Изписване']}, {'главоболие': ['главоболието', 'главобалие', 'главоблие', 'главололие']}, {'години': ['годинин']}, {'има': []}, {'След': []}, {'оплаква': ['оплакава', 'оплакваа', 'оплакваот']}, {'редовно': ['проведено', 'Проведено', 'редовна', 'редовен', 'проведен', 'нередовно', 'нередовна', 'увредено', 'Проведен', 'нередовен', 'Увредено', 'Нередовен', 'вродена', 'Нередовно']}, {'без': []}, {'лекарства': ['лекарствата', 'лекарство', 'лекарстава', 'лекаства', 'лекарстванта', 'лекарств', 'Залекарствата', 'лекарската', 'лекарството', 'лекарствa', 'лекарстваи', 'лекерства', 'лекарствена']}, {'отпадналост': ['Отпадналост', 'последната', 'отпаднала', 'отпаднал', 'отпадналос', 'отпоследната', 'отпаднталост', 'отпасналост']}, {'карцином': ['карцинома', 'корцином', 'карциномна', 'карцино', 'закорцином', 'крацином']}, {'със': ['ъс', 'съ']}, {'химиотерапия': ['химеотерапия', 'химиотерапии', 'химиотерапията', 'хормонотерапия', 'трахеотомия', 'химиотерапиите', 'полихимиотерапия', 'ихимиотерапия']}, {'кашлица': ['кашиляца']}, {'контрол': ['контролен', 'контролна', 'контролни', 'контрола', 'контрл', 'контролно', 'контрлна', 'котролен', 'конторлен', 'контроланата', 'торакално', 'контролнo', 'контрлони', 'корлентор', 'иконтрол', 'ксонтрол', 'конторлни']}, {'корема': ['коремна']}, {'контролен': ['контрол', 'коленете', 'колоректален', 'контрл', 'контролно', 'електро', 'котролен', 'неколкократно', 'конролен', 'некоколкократно', 'конторлен', 'контролните', 'корлентор']}, {'област': ['областта', 'слабост', 'областа', 'отслабнала', 'отслабнал', 'болеста', 'Слабост', 'обалстта', 'областан']}, {'лесна': []}, {'хоспитализация': ['хоспитализации', 'хоспитализацията', 'хоспиталицзация', 'хоспиталризация', 'хоспитализаия', 'хоспиталозация', 'хоспитализиция', 'хоспитализаци']}, {'умора': ['умоора']}, {'изследвания': ['изследване', 'изслевания', 'изследвания-не', 'иследвания', 'изследнавия', 'Изследвания', 'изслидвания', 'неизследвана', 'изледвания', 'изслидване', 'изследаване', 'изследванията']}, {'хипертония': ['хипертонията', 'хипертоиня', 'хипертонияс', 'хипертон', 'хиперотония', 'хипертонаия']}, {'дни': ['днии']}, {'състояние': ['състоянието', 'Състояние', 'сътоянието', 'Състоянието']}, {'DATE': []}, {'уриниране': ['нарушение', 'урениране', 'уриниране-уриниране', 'уринаране.на', 'еуринирал', 'уринарие']}, {'световъртеж': ['световъртежи', 'светонъртежът', 'световъртежа', 'светъвъртеж', 'световърт']}, {'сърцебиене': ['съцебиене']}, {'Има': []}, {'консултация': ['консултации', 'консултацияс', 'консултацция', 'консулгтация', 'конслутация', 'коинсултация', 'консултациас', 'конултация', 'консултацияас', 'консултаия', 'уонсултация', 'консултациа', 'кансултация', 'законсултация', 'сонсултацията']}, {'лява': ['влява']}, {'момента': ['моментта', 'Вмомента', 'монета', 'отнамалено', 'моментане', 'оментума']}, {'към': []}, {'оперирана': ['опериран', 'оперира', 'опереран', 'соперирана', 'оперина', 'оперираната', 'реоперарирана', 'Прооперирана', 'оперирани', 'оперерирана', 'оперерина', 'операатино', 'опеирана', 'оперираня', 'оператино', 'оперирано', 'оперитан']}, {'тежест': []}, {'год': []}, {'може': []}, {'заболявания': ['заболявания.', 'заболявания-на', 'заболявани']}, {'Оперирана': ['Опериран', 'Опириран', 'Оперира', 'Оперерирана', 'Опепиран']}]\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "top_unigrams_count = round(len(unigrams) * 0.03)\n",
    "top_unigrams = unigrams[0:top_unigrams_count]\n",
    "\n",
    "top_mistakes = []\n",
    "\n",
    "for unigram, _ in top_unigrams:\n",
    "    if len(unigram) < 3: continue\n",
    "    mistakes = { unigram: [] }\n",
    "    for other_unigram, _ in unigrams:\n",
    "        distance = jaccard_distance(set(unigram), set(other_unigram))\n",
    "        if distance < 0.15 and unigram != other_unigram:\n",
    "            mistakes[unigram].append(other_unigram)\n",
    "    top_mistakes.append(mistakes)\n",
    "\n",
    "print('====First 50 unigram mistakes====')\n",
    "print(top_mistakes[0:50])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
