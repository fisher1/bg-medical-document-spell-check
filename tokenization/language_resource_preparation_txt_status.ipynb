{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data_per_simpCode_00_clean_status.txt', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "df = pd.DataFrame(lines, dtype='string')\n",
    "#df=pd.read_table('../data_per_simpCode_00_clean_status.txt', sep='\\n', engine='python', header=None, encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean with regular expressions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numbers(sentence):\n",
    "    return re.sub('\\d+', 'NUM', sentence)\n",
    "\n",
    "def replace_float_numbers(sentence):\n",
    "    return re.sub('NUM.NUM', 'NUM', sentence)\n",
    "\n",
    "def remove_multiple_spaces(sentence):\n",
    "    return re.sub('\\s+', ' ', sentence)\n",
    "\n",
    "def remove_multiple_tabs(sentence):\n",
    "    return re.sub('\\t+', ' ', sentence)\n",
    "\n",
    "def space_out_semicolon(sentence):\n",
    "    return re.sub(';', ' ; ', sentence)\n",
    "\n",
    "def add_space_before_numbers(sentence):\n",
    "    return re.sub(r\"(\\w+)NUM\", r\"\\1 NUM\", sentence)\n",
    "\n",
    "def add_space_after_numbers(sentence):\n",
    "    return re.sub(r\"NUM(\\w+)\", r\"NUM \\1\", sentence)\n",
    "\n",
    "def remove_semicolons(sentence):\n",
    "    return re.sub(';', ' ', sentence)\n",
    "\n",
    "def remove_colons(sentence):\n",
    "    return re.sub(':', ' ', sentence)\n",
    "\n",
    "def remove_commas(sentence):\n",
    "    return re.sub('\\,', ' ', sentence)\n",
    "\n",
    "def remove_slashes(sentence):\n",
    "    return re.sub('\\/+', ' ', sentence)\n",
    "\n",
    "def remove_backslashes(sentence):\n",
    "    return re.sub('\\\\\\\\+', ' ', sentence)\n",
    "\n",
    "def remove_plus_signs(sentence):\n",
    "    return re.sub('\\+', ' ', sentence)\n",
    "\n",
    "def remove_underscores(sentence):\n",
    "    return re.sub('\\_', ' ', sentence)\n",
    "\n",
    "def replace_invalid_dash(sentence):\n",
    "    return re.sub('–', '-', sentence)\n",
    "\n",
    "def replace_multiple_dashes(sentence):\n",
    "    return re.sub('-{2,}', ' - ', sentence)\n",
    "\n",
    "def replace_multiple_dots(sentence):\n",
    "    return re.sub('\\.{2,}', '.', sentence)\n",
    "\n",
    "def remove_dashes_followed_by_space(sentence):\n",
    "    return re.sub(r\"(.)-\\s\", r\"\\1 \", sentence)\n",
    "\n",
    "def remove_dashes_following_a_space(sentence):\n",
    "    return re.sub(r\"\\s-(.)\", r\" \\1\", sentence)\n",
    "\n",
    "def remove_negative_examination(sentence):\n",
    "    return re.sub('\\(-\\)', ' ', sentence)\n",
    "\n",
    "def remove_starting_special_characters(sentence):\n",
    "    return re.sub('^[\\.\\?\\-,]+', '', sentence)\n",
    "\n",
    "def remove_ending_special_characters(sentence):\n",
    "    return re.sub('[\\.\\?\\-,]+$', '', sentence)\n",
    "\n",
    "def remove_dots(sentence):\n",
    "    return re.sub('[\\.]+', ' ', sentence)\n",
    "\n",
    "def remove_quotation_marks(sentence):\n",
    "    return re.sub('[\\`\\'\\\"]+', ' ', sentence)\n",
    "\n",
    "def remove_dot_before_word(sentence):\n",
    "    return re.sub(r\"([^\\wа-яА-Я])\\.([\\wа-яА-Я])\", r\"\\1 \\2\", sentence)\n",
    "\n",
    "def remove_dot_followed_by_dash(sentence):\n",
    "    return re.sub(r\"\\.\\-\", '. ', sentence)\n",
    "\n",
    "def space_out_dot_before_number(sentence):\n",
    "    return re.sub(r\"[\\.][\\-=]NUM\", '. NUM', sentence)\n",
    "\n",
    "def split_words_with_capital_after_lowercase(sentence):\n",
    "    return re.sub(r\"([а-яa-z])([А-ЯA-Z])\", r\"\\1 \\2\", sentence)\n",
    "\n",
    "\n",
    "df['clean_sentence'] = df[0].apply(remove_semicolons)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_colons)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_commas)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_slashes)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_backslashes)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_plus_signs)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_underscores)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_invalid_dash)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_multiple_dashes)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_multiple_dots)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_followed_by_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_following_a_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_negative_examination)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_starting_special_characters)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_ending_special_characters)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_float_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(add_space_before_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(add_space_after_numbers)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(space_out_dot_before_number)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dot_before_word)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dot_followed_by_dash)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(split_words_with_capital_after_lowercase)\n",
    "# df['clean_sentence'] = df['clean_sentence'].apply(remove_dots) # commetnt this line\n",
    "# df['clean_sentence'] = df['clean_sentence'].apply(space_out_semicolon)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_quotation_marks)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_multiple_tabs)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_multiple_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special cases cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dash_after_special_words(sentence):\n",
    "    special_words = [\n",
    "        'апарат', 'вени', 'възли', 'глава', 'гърло', 'далак', 'дейност', 'дроб', 'език',\n",
    "        'жлеза', 'жлези', 'зрение', 'кожа', 'корем', 'крайници', 'нос', 'ода', 'одс', \n",
    "        'простата', 'пулмо', 'пулс', 'рефлекси', 'с-ма', 'слезка', 'сливици', \n",
    "        'слух', 'статус', 'сърце', 'състояние',\n",
    "        'тегло', 'температура', 'тонзили', 'шия', 'чмн', 'rr']\n",
    "    for word in special_words:\n",
    "        sentence = re.sub(f\"({word})-\", r\"\\1 \", sentence, flags=re.IGNORECASE)\n",
    "    return sentence\n",
    "\n",
    "def replace_special_expressions(sentence):\n",
    "    special_expressions = [\n",
    "        ['V O S', 'VOS'],\n",
    "        ['V O D', 'VOD'],\n",
    "        [r\"([^\\wа-яА-Я])(?:рр|РР|Рр|rr|PP)\", r\"\\1 RR\"],\n",
    "        [r\"(?:рр|РР|Рр|rr|PP)([^\\wа-яА-Я])\", r\"RR \\1\"],\n",
    "        [r\"([^\\wа-яА-Я]*)(?:кор|Кор|КОР|kor|Кор)([^\\wа-яА-Я])\", r\"\\1 Cor \"],\n",
    "        [r\"(?:б\\.о\\.|\\sБО\\s|\\sБо\\s|\\sбо\\s|\\sб\\sо\\s|\\sБ\\sО\\s)\", ' б.о. '],\n",
    "        [r\"(?:РСД|р\\.с\\.д\\.|рсд|PCД)\", ' РСД '],\n",
    "        ['ССС', ' ССС '],\n",
    "    ]\n",
    "    for find, replace in special_expressions:\n",
    "        sentence = re.sub(find, replace, sentence)\n",
    "    return sentence\n",
    "\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dash_after_special_words)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(replace_special_expressions)\n",
    "\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_followed_by_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dashes_following_a_space)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_dot_before_word)\n",
    "df['clean_sentence'] = df['clean_sentence'].apply(remove_multiple_spaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Unigrams length====\n",
      "38948\n",
      "====First 50 unigrams====\n",
      "[('и', 29810), ('без', 27007), ('на', 23444), ('RR', 21816), ('б.о', 21280), ('Корем', 17228), ('Cor', 16859), ('в', 14394), ('дишане', 14238), ('мек', 12802), ('РСД', 12269), ('тонове', 11823), ('с', 10757), ('отоци', 10030), ('не', 9508), ('дейност', 9071), ('се', 8551), ('ясни', 8517), ('Пулмо', 8508), ('мин', 8200), ('Крайници', 7744), ('везикуларно', 7612), ('сърдечна', 6903), ('хрипове', 6524), ('неболезнен', 6524), ('за', 6213), ('дроб', 5956), ('ритмична', 5503), ('статус', 5341), ('общо', 5233), ('двустранно', 5136), ('ССС', 5118), ('по', 4644), ('уд', 4573), ('см', 4539), ('състояние', 4447), ('палпират', 4398), ('слезка', 4385), ('вез', 4338), ('крайници', 4212), ('АН', 4083), ('чисто', 4004), ('Кожа', 3829), ('шумове', 3581), ('болезнен', 3567), ('сърд', 3539), ('отр', 3376), ('тон', 3229), ('пулсации', 3198), ('лигавици', 3120)]\n",
      "====First 50 bigrams====\n",
      "[(('Корем', 'мек'), 9180), (('без', 'отоци'), 7393), (('везикуларно', 'дишане'), 7013), (('Cor', 'РСД'), 6939), (('сърдечна', 'дейност'), 6612), (('ясни', 'тонове'), 6034), (('не', 'се'), 5914), (('RR', 'Корем'), 4430), (('се', 'палпират'), 4302), (('дишане', 'без'), 4297), (('Крайници', 'без'), 4289), (('и', 'слезка'), 4001), (('мек', 'неболезнен'), 3966), (('вез', 'дишане'), 3722), (('ритмична', 'сърдечна'), 3500), (('общо', 'състояние'), 3311), (('тонове', 'без'), 3233), (('уд', 'мин'), 3134), (('дроб', 'и'), 3116), (('без', 'хрипове'), 2974), (('Черен', 'дроб'), 2905), (('без', 'прибавени'), 2886), (('РСД', 'ясни'), 2846), (('Кожа', 'и'), 2792), (('мин', 'RR'), 2664), (('Cor', 'ритмична'), 2431), (('БЯЛ', 'ДРОБ'), 2355), (('чисто', 'везикуларно'), 2347), (('прибавени', 'шумове'), 2163), (('дишане', 'Cor'), 2150), (('в', 'норма'), 2118), (('ССС', 'РСД'), 2076), (('данни', 'за'), 1891), (('и', 'видими'), 1873), (('перкуторен', 'тон'), 1866), (('не', 'болезнен'), 1845), (('Добро', 'общо'), 1764), (('слезка', 'не'), 1700), (('Пулмо', 'чисто'), 1691), (('сърд', 'дейност'), 1677), (('пулсации', 'на'), 1659), (('видими', 'лигавици'), 1659), (('дейност', 'ясни'), 1656), (('слезка', 'неувеличени'), 1650), (('б.о', 'Крайници'), 1637), (('при', 'палпация'), 1610), (('нивото', 'на'), 1580), (('шумове', 'RR'), 1538), (('мек', 'не'), 1528), (('ясен', 'перкуторен'), 1478)]\n"
     ]
    }
   ],
   "source": [
    "# save cleaned data so we know what tokenizer works on\n",
    "df['clean_sentence'].to_csv('sentence_cleaned_status.csv')\n",
    "\n",
    "discarded_tokens = ['.', 'NUM']\n",
    "\n",
    "unigrams = {}\n",
    "bigrams = {}\n",
    "for sentence in df['clean_sentence']:\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tokens = list(filter(lambda token: token not in discarded_tokens, tokens))\n",
    "\n",
    "    #get unigrams\n",
    "    for token in tokens:\n",
    "        if token not in unigrams:\n",
    "            unigrams[token] = 0\n",
    "        unigrams[token] += 1\n",
    "\n",
    "    #get bigrams\n",
    "    bigram_list = list(ngrams(tokens, 2))\n",
    "    for bigram in bigram_list:\n",
    "        if bigram not in bigrams:\n",
    "            bigrams[bigram] = 0\n",
    "        bigrams[bigram] += 1\n",
    "\n",
    "unigrams = sorted(unigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "bigrams = sorted(bigrams.items(), key=lambda x: x[1], reverse=True)\n",
    "print('====Unigrams length====')\n",
    "print(len(unigrams))\n",
    "print('====First 50 unigrams====')\n",
    "print(unigrams[0:50])\n",
    "print('====First 50 bigrams====')\n",
    "print(bigrams[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Collocations length====\n",
      "2549\n",
      "====First 50 collocations====\n",
      "[('ПИКОЧО-ПОЛОВО', 'С-МА'), ('МАНУАЛНО', 'ИЗСЛ'), ('Артериално', 'налягане'), ('(', 'Score'), ('Score', ')'), ('Съдечен', 'статус'), ('Корем', 'меко-еластичен'), ('везиколарно', 'дишане'), ('сърд', 'гран'), ('на', 'дебелото'), ('се', 'установява'), ('Ч.ДР', 'И'), ('на', 'артериите'), ('на', 'гръд.кош'), ('смущ', 'в'), ('без', 'доб'), ('доб', 'хрипове'), ('Авто', 'и'), ('рефлекси', 'Отпадна'), ('РСД', 'яс'), ('яс', 'тон'), ('сърд', 'гран.в'), ('гран.в', 'норма'), ('НА', 'ВЪРХА'), ('Цветно', 'зрение'), ('на', 'Аорта'), ('Аорта', 'RR'), ('Височина', 'см'), ('С-Фр.NUM', 'у'), ('Об.талия', 'см'), ('мм', 'Нв'), ('Нв', 'Корем'), ('мек', 'респиратнорно'), ('респиратнорно', 'подвижен'), ('за', 'ХСМ.Мек'), ('ХСМ.Мек', 'Физ'), ('без', 'хроп'), ('хроп', 'находка'), ('ритмична', 'сър.д-ст'), ('Оглед', 'палпация'), ('Пулсова', 'честота'), ('от', 'Крайничци'), ('Крайничци', 'леки'), ('Мекоеластична', 'коремна'), ('лимни', 'възли'), ('ЗА', 'ВЪЗРАСТТА'), ('Шиини', 'вени'), ('НЕВРОЛОГИЧИН', 'СТАТУС'), ('на', 'аа.дорзалис'), ('с', 'изтръпвания')]\n"
     ]
    }
   ],
   "source": [
    "def get_collocations(bigrams, freq_threshold=1):\n",
    "    collocations = []\n",
    "\n",
    "    bigram_map_first_word = {}\n",
    "    bigram_map_second_word = {}\n",
    "    for bigram, _ in bigrams:\n",
    "        if bigram[0] not in bigram_map_first_word:\n",
    "            bigram_map_first_word[bigram[0]] = 0\n",
    "        bigram_map_first_word[bigram[0]] += 1\n",
    "        if bigram[1] not in bigram_map_second_word:\n",
    "            bigram_map_second_word[bigram[1]] = 0\n",
    "        bigram_map_second_word[bigram[1]] += 1\n",
    "\n",
    "    for bigram, freq in bigrams:\n",
    "        if freq < freq_threshold:\n",
    "            continue\n",
    "        if bigram_map_first_word[bigram[0]] == 1 or bigram_map_second_word[bigram[1]] == 1:\n",
    "            collocations.append(bigram)\n",
    "\n",
    "    return collocations\n",
    "\n",
    "collocations = get_collocations(bigrams, 5)\n",
    "\n",
    "print('====Collocations length====')\n",
    "print(len(collocations))\n",
    "print('====First 50 collocations====')\n",
    "print(collocations[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====First 50 unigram mistakes====\n",
      "[{'без': ['безз', 'безе', 'ебез']}, {'б.о': ['б.о.', 'бо.о', 'бо.', 'б.оо', 'бб.о']}, {'Корем': ['Корме']}, {'Cor': []}, {'дишане': ['вдишване', 'дишанес', 'дишанел', 'издишане', 'дишаен', 'диишане', 'диашне', 'дишване', 'дишишане', 'дишанне', 'диша-не', 'деишане', 'дишанеи', 'дишавне', 'дишание', 'иьдишане', 'дишане.', 'дишанеRR', 'дишанев', 'дишанееедри', 'дишанеез', 'дзишане', 'идишване', 'дишарне', 'дишанене', 'дишаяне', 'издишнане']}, {'мек': []}, {'РСД': ['РДС', 'СРД', 'ДРС']}, {'тонове': ['тоновете', 'тоонве', 'тононве', 'товнове', 'тоонове', 'тонве', 'ттонове', 'тнове', 'тоновет', 'тоннове', 'тоновве', 'тонвое', 'тонтове', 'тооннове']}, {'отоци': ['оттоци', 'отци', 'тоци', 'отоиц', 'оитоци', 'отооци', 'ототци']}, {'дейност': ['дейнос', 'с.дейност', 'деност', 'дейост', 'дейност.', 'дейнот', 'дейности', 'дейносст', 'дейноскт', 'десното', 'деййност', 'дейнст', 'дейножст', 'деайност', 'дейниост', 'дейностс', 'десност', 'дейнсот', 'дейностq', 'дейностг', 'дейносттон', 'съдейност', 'сденост', 'съддейност', 'пдейност', 'денйност']}, {'ясни': ['сясни', 'иясни', 'ясин', 'яснии', 'синя', 'яясни']}, {'Пулмо': ['Пуллмо', 'Пулмоо']}, {'мин': ['мини', 'мни']}, {'Крайници': ['Краиници', 'Крайничци', 'Крайнициш', 'Краници', 'Крайнци', 'Крайни', 'Крйници', 'Крайнициб', 'Крайниц', 'Крайнеици', 'Кранйици', 'Ккрайници', 'Карйници', 'Кайници', 'Краайници', 'Краиниц', 'райници', 'Крайненици', 'Крайнници', 'Крайнишци', 'Краийници', 'Крайницис', 'Крайниции']}, {'везикуларно': ['везиколарно', 'визикуларно', 'везиуларно', 'везекуларно', 'везикуларна', 'везикларно', 'везикурарно', 'везикулрно', 'везикуларн', 'везикуларнор', 'везкуларно', 'езикуларно', 'везикуларни', 'везинуларно', 'везикуларен', 'взикуларно', 'нормовезикуларно', 'нормовезикуларноо', 'везикуларноя', 'веикуларно', 'везикулано', 'везикулорно', 'везикуларноq', 'везиукларно', 'везикулерно', 'везикулар-но', 'везикулавно', 'везиккуларно', 'везикуларво', 'везикуларено', 'вевикуларно', 'свезикуларно', 'везикурларно', 'везикеларно', 'твезикуларно', 'везикуларнно', 'везикурално', 'везикуларано', 'везилуларно', 'везикуларо', 'везикуларнао']}, {'сърдечна': ['сърдечната', 'сардечна', 'сърдечен', 'ърдечна', 'сърдена', 'съдечна', 'сърдечн', 'сърдчна', 'дърдечна', 'сърдечан', 'нсърдечна', 'сръдечна', 'сърдечне', 'сърдейчна', 'дсърдечна']}, {'хрипове': ['хипове', 'хрипов', 'хрипове.', 'хпихове', 'пр.хрипове', 'хрепове', 'хриповев', 'припове', 'хрипови', 'рипове', 'хрпове', 'хрипое', 'хирпове', 'iхрипове', 'хриповеe', 'хрлипове', 'хрпипове', 'хрипве', 'хрипове-', 'хрипшове', 'хриповер', 'хриево', 'хропове', 'хрпиове', 'хриповае', 'хриппове', 'хриове', 'ихрипове', 'хриповед', 'хпипове', 'хриипове', 'хрипоев', 'хрипиове', 'хриепове', 'хирове', 'хрирове', 'хриповехрипове', 'хриповме', 'хрипояве', 'свхрипове', 'хриповее', 'хришпове']}, {'неболезнен': ['болезнен', 'болезнени', 'болезнена', 'неболезнена', 'неболезнени', 'болезн', 'болезнено', 'неболезнено', 'Неболезнен', 'безболезнен', 'неболезен', 'неболезн', 'болезнене', 'безболезнена', 'иболезнени', 'болезне', 'болезен', 'заоблен', 'неболезнене', 'неболез', 'болезненна', 'неболзнен', 'неболезне', 'болезненос', 'болзнени', 'неболзнено', 'болезненв', 'неболезненен', 'неболезенен', 'иболезнини', 'неболезнен.', 'неболезнне', 'неболазнен', 'безболезнени', 'болзенени', 'лекоболезнен', 'неболезнеин', 'неболезннен', 'безполезнен', 'Неболезнено', 'неболезтен', 'болезннен', 'меболезнен', 'болзенен', 'болезнео', 'болезнение', 'болезени', 'оболезнен', 'неболуезнен', 'болезнев', 'болезене', 'болезенен', 'болезненот', 'неболезненна', 'неболезненн', 'неболезненр', 'небелознен', 'болезннени', 'болезненин', 'неболезненно', 'неаболезнен', 'нeболезнен', 'болезнес', 'неболезнан', 'небелезнено', 'болезненен', 'биолезнени', 'болезненн', 'болезнении', 'болезнне', 'болеузнен', 'болезна', 'неболезна', 'болезнеин', 'болезнепо', 'болезненс', 'болзезна', 'болеззнен', 'безболезн', 'болезненл', 'болезннене', 'боллезнен', 'неболезненена', 'болзенен.', 'болезнен.', 'болезненпо', 'необолезнен', 'болезенн', 'болеезнен', 'неболерзнен', 'болзнен']}, {'дроб': ['добро', 'дрбо', 'ддроб', 'дбро']}, {'ритмична': ['аритмична', 'ритмични', 'Аритмична', 'риттмична', 'aритмична', 'итмична', 'тахиаритмична', 'тахиритмична', 'травматична', 'неритмична', 'травматични', 'Aритмична', 'ритмечна', 'римична', 'ритъмична', 'норморитмична', 'ритмимчна', 'ретмична', 'аритмичан', 'ртмична', 'ритминта', 'ритмичн', 'ритимчина', 'ритимична', 'ритмчина', 'аитмична', 'р.итмична', 'аретмична', 'тмична', 'Рритмична', 'аритмича', 'а-ритмична', 'аритмичен', 'ритмичан', 'ринмична', 'артмична', 'нормоаритмична', 'ритмчна']}, {'статус': ['сатус', 'статуса', 'устата', 'уста', 'стаус', 'статсу', 'саттус', 'сттатус', 'статусстатус', 'стату', 'сатсу', 'устатата']}, {'общо': ['общ', 'бщо', 'ообщо', 'бощо', 'обощо', 'обощ']}, {'двустранно': ['отр.двустранно', 'двустранна', 'двустрано', 'двустанно', 'двустраннно', 'двустранн', 'двусранно', 'двустронно', 'двустранно.', 'двустрана', 'двустарнно', 'двустранноо', 'отр-двустранно', 'двустрнно', 'двустранносу', 'свустранно', 'отрдвустранно', 'вустранно', 'двустрнанно', 'двудстранно', 'двустранноневр', 'двмустранно', 'дувстарно', 'двустранвно', 'двеустранно', 'двустнано', 'ср-двустрранно', 'двустранно-отр', 'двустрно', 'двустарно', 'двустранноъ', 'вдустранно', 'двусвтранно', 'двустранно-', 'двстрано', 'двустраннои', 'двустраннол', 'двустронна', 'двустраннна', 'двустлранно', 'двукстранно', 'др-двустранно']}, {'ССС': ['С', 'СС']}, {'състояние': ['Състояние', 'състоянието', 'сътояние', 'съсояние', 'съсотяние', 'състоние', 'състяние', 'състояние.', 'състояния', 'състояни', 'съсътояние', 'Състоянието', 'състоятие', 'състояниесле', 'състояниел', 'стояние', 'състтояние', 'състиояниее', 'състояниеие', 'състояниеи', 'съсотянние', 'състояниета', 'състоянояние', 'съсстояние', 'състоянние', 'дсъстояние', 'состояние', 'състоняие', 'състояниеRR', 'съответния', 'състояие', 'сдъстояние', 'състояниуе', 'състояниие', 'съътояние', 'стени-състояние', 'състояпние', 'ссътояние', 'състояниее', 'ъсстояание', 'състоянвие', 'състоянуие', 'сътсояние', 'състояание', 'състояяние', 'състояниео', 'състотояние', 'ссътояни']}, {'палпират': ['Палпират', 'сапалпират', 'правилата', 'палират', 'палпират.', 'епалпират', 'палпирта', 'полпират', 'алпират', 'палпирт', 'полиартр', 'палпирата', 'палпираат', 'палипрат', 'палпирет', 'палпиурат', 'палпхират', 'спалпират', 'ппалпират', 'полиартрит', 'палпирлат', 'палппират']}, {'слезка': ['сл.езка', 'ислезка', 'слезката', 'слезкане', 'слезска', 'слезак']}, {'вез': ['зев', 'взе', 'звез']}, {'крайници': ['крайник', 'краиници', 'крайника', 'крайни', 'крйници', 'краници', 'крайниц', 'Ккрайници', 'крайнииц', 'ккрайници', 'райник', 'крайници.', 'икрайници', 'райници', 'крайницици', 'крайница', 'крайици', 'крайнци', 'краяйници', 'кракници', 'краойници', 'крайнициб', 'крайницини', 'карйниц', 'красйници', 'крайнице', 'накрайници', 'крайиници', 'крайъници']}, {'чисто': ['ичисто', 'чисот', 'чистоо', 'чиссто']}, {'Кожа': []}, {'шумове': ['шумовес', 'шумове.', 'шумовео', 'шумовете', 'шумовеч', 'шуммове', 'шумовве']}, {'болезнен': ['неболезнен', 'болезнени', 'болезнена', 'неболезнена', 'неболезнени', 'болезн', 'болезнено', 'неболезнено', 'Неболезнен', 'безболезнен', 'неболезен', 'неболезн', 'болезнене', 'безболезнена', 'иболезнени', 'болезне', 'болезен', 'заоблен', 'неболезнене', 'неболез', 'болезненна', 'неболзнен', 'неболезне', 'болезненос', 'болзнени', 'неболзнено', 'болезненв', 'неболезненен', 'неболезенен', 'иболезнини', 'неболезнен.', 'неболезнне', 'неболазнен', 'безболезнени', 'болзенени', 'лекоболезнен', 'неболезнеин', 'неболезннен', 'безполезнен', 'Неболезнено', 'неболезтен', 'болезннен', 'меболезнен', 'болзенен', 'болезнео', 'болезнение', 'болезени', 'оболезнен', 'неболуезнен', 'болезнев', 'болезене', 'болезенен', 'болезненот', 'неболезненна', 'неболезненн', 'неболезненр', 'небелознен', 'болезннени', 'болезненин', 'неболезненно', 'неаболезнен', 'нeболезнен', 'болезнес', 'неболезнан', 'небелезнено', 'болезненен', 'биолезнени', 'болезненн', 'болезнении', 'болезнне', 'болеузнен', 'болезна', 'неболезна', 'болезнеин', 'болезнепо', 'болезненс', 'болзезна', 'болеззнен', 'безболезн', 'болезненл', 'болезннене', 'боллезнен', 'неболезненена', 'болзенен.', 'болезнен.', 'болезненпо', 'необолезнен', 'болезенн', 'болеезнен', 'неболерзнен', 'болзнен']}, {'сърд': []}, {'отр': ['тор', 'орт']}, {'тон': ['отн', 'тоно']}, {'пулсации': ['пулсац', 'пулсаций', 'пулсация', 'пулсаци', 'пуслации', 'пулсции', 'пулсациии', 'пулсациина', 'пулсацци', 'пусации', 'пулксации', 'пулации', 'пулсациеи', 'пяулсации', 'пуласации', 'пулсацици', 'пулсаии', 'пилсации', 'поулсации', 'опулсации', 'пулсцаии', 'плсации', 'пулациии', 'пулсации.', 'пулсацие', 'пулцации', 'пулосации']}, {'лигавици': ['лигавица', 'илигавици', 'лигавицци', 'лигавицата', 'лигамвици', 'легавици', 'илгавици', 'лигавиции', 'лигаваци', 'лигавици-в', 'лигавице', 'лгавици', 'лигавиц', 'лигавмици', 'лигавициб', 'лигавиица', 'лигваци', 'лигавиици', 'лигагавици', 'лагивици']}, {'норма': ['нормано', 'норама']}, {'ОДА': []}, {'прибавени': ['прибавни', 'прибавена', 'направени', 'прибавен', 'прибавеи', 'пврибавени', 'пребавени', 'приавени', 'прибавеин', 'прибевени', 'нрибавени', 'прибавениш', 'прибанене', 'прибавнени', 'прибарени']}, {'Черен': []}, {'неувеличени': ['увеличени', 'увеличена', 'неувеличена', 'неувеличен', 'увеличен', 'Неувеличени', 'увелич', 'неувелич', 'лиен-неувеличени', 'не-увелич', 'неувелечени', 'нeувеличени', 'нуевеличени', 'увелечени', 'лиеннеувел', 'увеличение', 'неувеличини', 'неувеличени.', 'невеличени', 'неувеличеи', 'лиен-неувелич', 'увеличения', 'неувиличени', 'увеличени.', 'неувелличени', 'неуваличени', 'увелечен', 'величени', 'неувеличено', 'увеличеин', 'нувеличени', 'увеличин', 'увиличена', 'венули', 'увелични', 'увеличана', 'увеличенина', 'увеличини', 'неувеличении', 'увеличаване', 'увличена', 'увеличеви', 'неувеличе', 'неуверличени', 'увелиени', 'лиен-неувеличен', 'челвени', 'увеличено', 'неуеличени', 'неувуличени', 'увеличичена', 'нуевличени', 'увиличени', 'увеличанеа', 'хнеувеличени', 'пеувеличени', 'увуличена', 'увеливение', 'увеличчени', 'неувеличенa', 'увелечун', 'увелеличени', 'неувеличент', 'увелиичени', 'Неувличени', 'иувеличени', 'увелричен', 'нeувеличен', 'неувеличение', 'увеличе', 'увеличевни.', 'увличени', 'увелиличени', 'увеличенна', 'увеличенил', 'ниувеличени']}, {'жлеза': ['железа']}, {'Pulmo': []}, {'при': ['пир']}, {'КОРЕМ': ['КОРЕММЕК']}, {'ИТМ': []}, {'Чисто': []}, {'стени': ['ситен', 'стеснени', 'тесни', 'тнестис', 'стеснение', 'тенис']}]\n"
     ]
    }
   ],
   "source": [
    "from nltk.metrics.distance import jaccard_distance\n",
    "\n",
    "top_unigrams_count = round(len(unigrams) * 0.03)\n",
    "top_unigrams = unigrams[0:top_unigrams_count]\n",
    "\n",
    "top_mistakes = []\n",
    "\n",
    "for unigram, _ in top_unigrams:\n",
    "    if len(unigram) < 3: continue\n",
    "    mistakes = { unigram: [] }\n",
    "    for other_unigram, _ in unigrams:\n",
    "        distance = jaccard_distance(set(unigram), set(other_unigram))\n",
    "        if distance < 0.15 and unigram != other_unigram:\n",
    "            mistakes[unigram].append(other_unigram)\n",
    "    top_mistakes.append(mistakes)\n",
    "\n",
    "print('====First 50 unigram mistakes====')\n",
    "print(top_mistakes[0:50])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
